{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'there', \"that'll\", 'so', 'other', 'hadn', \"wouldn't\", \"won't\", 'weren', 'you', 'then', 'during', 'am', 'being', 'just', 'o', 'that', 'by', \"hasn't\", 'do', 'won', 'from', 'her', 'she', 'did', 'myself', \"you'll\", 'nor', 'more', 're', 'haven', \"shan't\", 'shouldn', 'your', 'himself', 'yourself', 'if', 'out', 'itself', 'these', 'isn', 'ma', 'off', 'its', 'most', 'at', 'both', 'only', \"needn't\", 'i', 'for', \"isn't\", 'into', 'is', 'them', 'had', 'ours', 'was', 'very', 'they', 'herself', 'has', 'about', 'me', 'can', \"you've\", 'why', \"you're\", 'between', 'wasn', \"weren't\", \"aren't\", 'my', 'having', 'mustn', 'of', 'we', \"haven't\", 'over', 'no', 'doing', 'what', 'does', 'should', 'not', 'before', 'needn', 'couldn', 'and', 'up', 'their', 'in', 'because', 'yours', 'above', 'aren', 's', 'who', 'some', 'wouldn', 'd', 'a', \"shouldn't\", \"you'd\", 'while', 'after', 'against', 'have', 'which', \"she's\", 'where', 'hers', 'this', 'those', 'all', 'below', 'will', 'shan', 'until', 'down', \"should've\", 'he', 'hasn', 'on', 'an', 'through', \"doesn't\", 'same', 've', 'didn', \"don't\", \"wasn't\", 'y', 'when', 'don', 'any', 'such', 't', 'doesn', 'with', 'ourselves', 'his', 'be', 'm', 'ain', \"it's\", 'the', 'were', 'few', 'yourselves', \"didn't\", \"mightn't\", 'as', 'to', 'whom', 'each', 'too', \"hadn't\", 'it', 'mightn', 'under', 'him', \"mustn't\", 'themselves', 'further', 'again', 'how', 'our', 'once', 'own', 'll', \"couldn't\", 'now', 'theirs', 'here', 'but', 'been', 'are', 'than', 'or'}\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deja', 'acelea', 'ceilalti', 'atita', 'ati', 'o', 'iti', 'dintre', 'pe', 'doi', 'asta', 'alea', 'alti', 'câţi', 'oricînd', 'săi', 'apoi', 'vostru', 'nou', 'spate', 'sa-ti', 'ceva', 'fiecare', 'ului', 'fără', 'sa', 'cărui', 'patra', 'te', 'său', 'suntem', 'noua', 'doilea', 'citiva', 'treilea', 'câtva', 'puţin', 'tăi', 'lîngă', 'ta', 'altcineva', 'si', 'va', 'unui', 'mei', 'incit', 'acele', 'citi', 'vor', 'abia', 'fata', 'desi', 'mai', 'multe', 'careia', 'nişte', 'fiu', 'toate', 'intre', 'ăla', 'ălea', 'fost', 'alt', 'acestea', 'voştri', 'până', 'le', 'celor', 'eu', 'sunt', 't', 'acestia', 'm', 'aici', 'şi', 'îi', 'ar', 'poate', 'tuturor', 'voastră', 'din', 'nouă', 'sus', 'imi', 'fim', 'oricare', 'unde', 'mă', 'avea', 'altii', 'mod', 'mea', 'eram', 'unora', 'se', 'acestui', 'oricând', 'cînd', 'adica', 'deci', 'uneori', 'ti', 'vouă', 'dată', 'caruia', 'altceva', 'orice', 'mulţi', 'care', 'oricît', 'tot', 'pot', 'ba', 'ca', 'catre', 'atitia', 'mâine', 'sau', 'numai', 'tu', 'vom', 'unul', 'li', 'acei', 'unu', 'patru', 'cine', 'este', 'dupa', 'tine', 'acelasi', 'meu', 'dat', 'mîine', 'deasupra', 'totul', 'peste', 'cum', 'in', 'aceste', 'aibă', 'vreo', 'către', 'lor', 'altfel', 'avut', 'cea', 'îţi', 'pina', 'fii', 'isi', 'astfel', 'undeva', 'una', 'aceasta', 'cât', 'cele', 'ele', 'citeva', 'sunteţi', 'unor', 'asupra', 'noştri', 'cit', 'ni', 'inapoi', 'fie', 'cei', 'ale', 'dintr', 'ia', 'iar', 'pînă', 'cîtva', 'în', 'alte', 'cărei', 'toti', 'il', 'noastră', 'dau', 'are', 'asa', 'fara', 'că', 'mine', 'ai', 'cîţi', 'mi', 'nici', 'multa', 'ci', 'e', 'ăstea', 'ţi', 'ne', 'aţi', 'ul', 'ţie', 'drept', 'toţi', 'toată', 'aceeasi', 'ma', 'noastre', 'ăştia', 'au', 'v', 'zi', 'atare', 'ăsta', 'carora', 'de', 'cat', 'oricum', 'chiar', 'primul', 'căror', 'noi', 'vreun', 'ea', 'câte', 'atit', 'treia', 'acela', 'voi', 'putini', 'foarte', 'acest', 'atata', 'voastre', 'sale', 'prea', 'a', 'atat', 'pic', 'nimic', 'altul', 'nostri', 'vi', 'uneia', 'cu', 'cîte', 'inca', 'avem', 'zice', 'multi', 'mele', 'fiţi', 'tale', 'cam', 'dă', 'fi', 'daca', 'cît', 'îl', 'unele', 'doar', 'cineva', 'intr', 'niste', 'dacă', 'prin', 'atatea', 'or', 'ceea', 'nu', 'căci', 'mie', 'parca', 'puţina', 'am', 'deşi', 'ii', 'decit', 'să', 'aş', 'ce', 'insa', 'acesta', 'sint', 'al', 'această', 'ori', 'inainte', 'unei', 'tocmai', 'nostru', 'lângă', 'vă', 'îmi', 'el', 'oriunde', 'eşti', 'astea', 'spre', 'i', 'cand', 'un', 'totuşi', 'acea', 'aceşti', 'atitea', 'la', 'aceea', 'cind', 'prima', 'tău', 'cita', 'toata', 'aia', 'dar', 'oricine', 'sai', 'ala', 'lui', 'atunci', 'fel', 'trei', 'era', 'aveţi', 'pai', 'sintem', 'sub', 'dintr-', 'unuia', 'cumva', 'aceştia', 'cui', 'ei', 'alta', 'nimeni', 'totusi', 'u', 'după', 'două', 'mereu', 'mult', 'unii', 'sa-mi', 'acestei', 'cel', 'multă', 'acel', 'as', 'printr-', 'aceia', 'pentru', 'atatia', 'da', 'anume', 'face', 'oricât', 'cite', 'despre', 'puţină'}\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('romanian'))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'so', 'dein', 'können', 'zwar', 'eure', 'unsere', 'hatte', 'er', 'zum', 'anderer', 'nun', 'sonst', 'bis', 'denn', 'desselben', 'derer', 'manche', 'meiner', 'welches', 'am', 'keine', 'dieser', 'waren', 'ich', 'aller', 'dasselbe', 'ins', 'meines', 'seine', 'wo', 'sie', 'des', 'alles', 'durch', 'dieselbe', 'hinter', 'sehr', 'diese', 'anderem', 'mit', 'seinem', 'welcher', 'manchen', 'dieses', 'einiger', 'jener', 'unserem', 'das', 'eine', 'nur', 'dessen', 'solche', 'dann', 'unser', 'noch', 'gegen', 'euer', 'zu', 'mich', 'aber', 'auf', 'sondern', 'sein', 'solchem', 'mein', 'euch', 'vom', 'nach', 'denselben', 'einigen', 'anders', 'keines', 'was', 'mir', 'hab', 'eures', 'meinen', 'wie', 'derselben', 'meine', 'wollte', 'um', 'einigem', 'hat', 'jeden', 'deines', 'unseres', 'ohne', 'andere', 'auch', 'ihm', 'ihre', 'soll', 'für', 'jenen', 'dich', 'meinem', 'daß', 'jenes', 'diesen', 'jede', 'wirst', 'unseren', 'bei', 'war', 'gewesen', 'diesem', 'einer', 'weiter', 'ihrem', 'würde', 'einige', 'keinen', 'solches', 'deine', 'jene', 'würden', 'während', 'von', 'in', 'könnte', 'hin', 'ein', 'damit', 'einiges', 'eurem', 'eurer', 'nichts', 'eines', 'ihn', 'kein', 'vor', 'dazu', 'alle', 'dass', 'jetzt', 'der', 'dort', 'ihr', 'ihnen', 'selbst', 'solchen', 'als', 'ihren', 'uns', 'wird', 'weil', 'aus', 'welche', 'allen', 'zwischen', 'machen', 'sind', 'dies', 'deiner', 'will', 'man', 'seines', 'wollen', 'deinem', 'du', 'dir', 'musste', 'hier', 'im', 'jenem', 'kann', 'seinen', 'deinen', 'manchem', 'an', 'anderm', 'einen', 'zur', 'nicht', 'andern', 'indem', 'dem', 'muss', 'solcher', 'anderen', 'sollte', 'unter', 'oder', 'warst', 'hatten', 'mancher', 'werde', 'seiner', 'jedes', 'einem', 'allem', 'anderes', 'doch', 'ihres', 'über', 'es', 'die', 'jeder', 'ihrer', 'einig', 'keiner', 'welchem', 'welchen', 'sich', 'anderr', 'da', 'weg', 'bin', 'wir', 'ob', 'ist', 'etwas', 'haben', 'habe', 'wenn', 'werden', 'manches', 'und', 'wieder', 'ander', 'euren', 'keinem', 'jedem', 'bist', 'den', 'demselben', 'dieselben', 'viel', 'derselbe', 'einmal', 'also'}\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('german'))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fussiez', 'seront', 'son', 'tes', 'soyez', 'se', 'seriez', 'mon', 'ai', 'ayants', 'étante', 'seraient', 'aurai', 'toi', 'ayant', 'ce', 'soyons', 'serions', 'pas', 'aurons', 'avaient', 'fussent', 'ait', 'soient', 'eus', 'dans', 'des', 'ne', 'avec', 'suis', 'fus', 'étions', 'sois', 'étants', 'ou', 'aient', 'avons', 'sommes', 'les', 'ma', 'eûmes', 'fusses', 'ton', 'au', 'votre', 'étés', 'ayantes', 'un', 'sa', 'tu', 'aura', 'qu', 'c', 'de', 'te', 'la', 'ayons', 'me', 'aies', 'vous', 'ses', 'moi', 'étées', 'serez', 'aviez', 'ta', 'fut', 'eussiez', 'même', 'eusses', 'l', 'serons', 'fûmes', 'ayez', 'vos', 'avions', 'serais', 'leur', 'eût', 'aurions', 'aurais', 'fusse', 'n', 'lui', 'été', 'auriez', 'et', 's', 'soit', 'eue', 'ils', 'd', 'avais', 'aie', 'auront', 'ces', 'serai', 'eurent', 'sur', 'étais', 'furent', 'eut', 'fût', 'du', 'étant', 'auras', 'était', 'notre', 'par', 'nos', 'on', 'étée', 'à', 'avait', 'ayante', 'eussions', 'aurait', 'aux', 'le', 'fussions', 'je', 'y', 'ont', 'eues', 'sera', 'qui', 'j', 'étaient', 'eu', 'que', 't', 'eux', 'es', 'm', 'êtes', 'étantes', 'fûtes', 'seras', 'aurez', 'avez', 'eûtes', 'en', 'as', 'mais', 'auraient', 'une', 'pour', 'serait', 'eusse', 'eussent', 'sont', 'étiez', 'est', 'nous', 'il', 'mes', 'elle'}\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('french'))\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"./training/clean/english\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "words = [word.lower() for word in tokens] # memove capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['history', 'jews', 'romania', 'history', 'jews', 'romania', 'concerns', 'jews', 'romania', 'romanian', 'origins', 'first', 'mention', 'present-day', 'romanian', 'territory', 'minimal', 'century', 'size', 'jewish', 'population', 'increased', 'around', 'especially', 'establishment', 'greater', 'romania', 'aftermath', 'world', 'war', 'diverse', 'community', 'albeit', 'overwhelmingly', 'urban', 'one', 'jews', 'target', 'religious', 'persecution', 'racism', 'romanian', 'society', 'late-th', 'century', 'debate', 'jewish', 'question', 'jewish', 'residents', 'right', 'citizenship', 'genocide', 'carried', 'lands', 'romania', 'part', 'holocaust', 'latter', 'coupled', 'successive', 'waves', 'aliyah', 'accounted', 'dramatic', 'decrease', 'overall', 'size', 'romania', 'present-day', 'jewish', 'community', 'jewish', 'communities', 'existed', 'romanian', 'territory', 'century', 'reign', 'peter', 'lame', 'jews', 'moldavia', 'mainly', 'traders', 'poland', 'competing', 'locals', 'taxed', 'ultimately', 'expelled', 'authorities', 'decided', 'required', 'jews', 'wear', 'clothing', 'evidencing', 'status', 'ethnicity']\n"
     ]
    }
   ],
   "source": [
    "#load English stop words\n",
    "stopWords = set(stopwords.words('english')) #153 stop words\n",
    "wordsFiltered = []\n",
    "\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    "#filter words <= 14 and >2 characters\n",
    "wordsLanguage = []\n",
    "for word in wordsFiltered:\n",
    "    if len(word) <= 14 and len(word) > 2:\n",
    "        wordsLanguage.append(word)\n",
    "print(wordsLanguage[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rheidol', 'escalates', 'framed', 'jillian', 'slamming', 'ts-n', 'worn', 'brassard', 'suspenseful', 'entombs', 'β-alanine', 'fike', 'gellar', 'permission', 'cottages', 'constipated', 'bridleways', 'gladiator', 'barn-style', 'rougier', 'stojanović', 'sidetrack', 'glacial', 'dub', 'shut', 'scourged', 'gustines', 'peacemakers', 'ceàrr', 'vruksha', 'shivaji', 'aearo', 'mendelssohn', 'derailed', 'respond', 'cleavage', 'otway', 'severan', 'julesz', 'mini-marathon', 'cdu', 'coveny', 'mendicants', 'substratum', 'ennobled', \"'cultivation\", 'unifying', 'clerical', 'seminarians', 'cassadaga', 'bathhouses', 'hobgoblins', 'bolbanabad', 'noor', \"'as-used\", 'timurid', 'mówiłeś', 'kooser', 'beyaz', 'six-tube', 'judging', 'rahman', 'changes', 'approximately', 'tshopo', 'invitee', 'transliterated', 'bulbflower', 'ast', 'gentle', 'floodplain', 'favorable', 'novosel', 'monsu', 'parthiv', 'solstice', 'transitive', 'bamiléké', 'bereavement', 'evian', 'wishing', 'theodosius', 'infectious', 'annealed', 'jardin', 'شاهنشاهی', 'sawdust', 'najma', 'tvta', 'ormskirk', 'mianwali', 'goalscoring', 'expounded', 'quadrillion', 'denti', 'cheapest', 'taveiro', 'tissot', 'mountaineers', 'muzaffarabad']\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate words\n",
    "uniqueWordsLanguage = list(set(wordsLanguage))\n",
    "print(uniqueWordsLanguage[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('en_words.txt', 'w') as filehandle:\n",
    "    for listitem in wordsLanguage:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('en_words_noduplicates.txt', 'w') as filehandle:\n",
    "    for listitem in uniqueWordsLanguage:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avrig', 'avrig', 'dialectul', 'săsesc', 'frek', 'fraek', 'oraș', 'județul', 'sibiu', 'transilvania', 'românia', 'format', 'localitatea', 'componentă', 'avrig', 'reședința', 'satele', 'bradu', 'glâmboaca', 'mârșa', 'săcădate', 'populație', 'locuitori', 'atestat', 'documentar', 'anul', 'fiind', 'declarat', 'oraș', 'aprilie', 'localitatea', 'avrig', 'amplasată', 'poalele', 'munților', 'făgăraș', 'valea', 'oltului', 'altitudine', 'aproximativ', 'metri', 'străbătută', 'șoseaua', 'națională', 'fiind', 'amplasată', 'circa', 'kilometri', 'sibiu', 'situat', 'într-un', 'adevărat', 'amfiteatru', 'natural', 'relieful', 'înalță', 'coboară', 'metri', 'avrigul', 'caracterizat', 'complex', 'variat', 'atât', 'structură', 'geologică', 'aspect', 'morfologic', 'latura', 'sudică', 'străjuită', 'crestele', 'făgărașilor', 'numiți', 'geograful', 'francez', 'martonne', 'alpii', 'transilvaniei', 'vârfurile', 'suru', 'budislavu', 'ciortea', 'scara', 'nord', 'avrigul', 'vecini', 'comuna', 'șelimbăr', 'comuna', 'nocrich', 'delimitate', 'muchia', 'chirmovului', 'dealul', 'nucului', 'măgura', 'est', 'avrigul', 'învecinează', 'porumbacu']\n"
     ]
    }
   ],
   "source": [
    "text = open(\"./training/clean/romanian\").read()\n",
    "tokens = word_tokenize(text)\n",
    "words = [word.lower() for word in tokens] # memove capitalization\n",
    "#load Romanian stop words\n",
    "stopWords = set(stopwords.words('romanian')) #153 stop words\n",
    "wordsFiltered = []\n",
    "\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    "wordsLanguage = []\n",
    "# remove words < 2 and >14 charachers\n",
    "for word in wordsFiltered:\n",
    "    if len(word) <= 14 and len(word) > 2:\n",
    "        wordsLanguage.append(word)\n",
    "print(wordsLanguage[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['călușul', 'dieckmann', 'concertând', 'korecki', 'framed', 'așevcenco', 'configuratia', 'biciuire', 'lins', 'pancromatice', 'peticea', 'gauck', 'prangins', 'bulevardelor', 'ți-aș', 'compatriotului', 'stadioane', 'înlocuiți', 'bănci', 'andezite', 'acuzându-i', 'újépület', 'gladiator', 'absente', 'intrarea', 'psihiatrice', 'sesizează', 'imunologice', 'valby', 'dub', 'shut', 'pasarile', 'norodom', 'ară', 'hipoglos', 'jgheab', 'traducerilor', 'shivaji', 'steagurilor', 'mendelssohn', 'sară', 'socoate', 'schöne', 'utr-uri', 'descătușările', 'ardelenește', 'dințată', 'perpetuu', 'asszonypataka', 'prelevate', 'judicii', 'polinom', 'nebunește', 'psihiatrului', 'deshumate', 'cdu', 'destrămarea', 'adăugarea', 'hazem', 'morencei', 'clișeului', 'erau', 'băneasă', 'revigoreze', 'pnk', 'clerical', 'epaminonda', 'maïtena', 'mixeze', 'ofereau', 'semicalotei', 'triasicul', 'tensionat', 'rõõm', 'inegală', 'oieritul', 'simulare', 'ice-tea', 'supererou', 'jassy', 'timurid', 'sabiei', 'psihosocială', 'răsturnările', 'funitelului', 'ionul', 'atrage', 'faxurilor', 'comedie', 'zoologică', 'bun-simț', 'sevei', 'sucul', 'mapaction', 'xviii-xx', 'operatorul', 'crivina', 'pămănt', 'șomăcescu', '-studiile']\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate words\n",
    "uniqueWordsLanguage = list(set(wordsLanguage))\n",
    "print(uniqueWordsLanguage[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ro_words.txt', 'w') as filehandle:\n",
    "    for listitem in wordsLanguage:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ro_words_noduplicates.txt', 'w') as filehandle:\n",
    "    for listitem in uniqueWordsLanguage:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paris', 'paris', 'hauptstadt', 'französischen', 'republik', 'hauptort', 'region', 'île-de-france', 'fluss', 'teilt', 'stadt', 'nördlichen', 'rive', 'droite', 'rechtes', 'ufer', 'südlichen', 'teil', 'rive', 'gauche', 'linkes', 'ufer', 'administrativ', 'stadtbezirke', 'unterteilt', 'mehr', 'millionen', 'einwohnern', 'paris', 'fünftgrößte', 'stadt', 'europäischen', 'union', 'sowie', 'millionen', 'menschen', 'london', 'zweitgrößte', 'metropolregion', 'kleinen', 'stadtfläche', 'paris', 'rund', 'einwohnern', 'pro', 'dichtesten', 'besiedelte', 'großstadt', 'europas', 'bebaute', 'städtische', 'unité', 'urbaine', 'paris', 'groß', 'geht', 'somit', 'weit', 'politische', 'grenze', 'kernstadt', 'hinaus', 'zählte', 'unité', 'urbaine', 'paris', 'einwohner', 'einwohnern', 'entspricht', 'womit', 'paris', 'megastädten', 'zählt', 'paris', 'politische', 'sowie', 'kulturelle', 'zentrum', 'zentralistisch', 'organisierten', 'frankreichs', 'drei', 'flughäfen', 'sechs', 'kopfbahnhöfen', 'größter', 'teile', 'seine-ufers', 'zählen', 'heute', 'stadt', 'sitz', 'unesco', 'darüber', 'hinaus', 'oecd', 'icc', 'eiffelturm', 'kathedrale', 'notre-dame']\n"
     ]
    }
   ],
   "source": [
    "text = open(\"./training/clean/german\").read()\n",
    "tokens = word_tokenize(text)\n",
    "words = [word.lower() for word in tokens] # memove capitalization\n",
    "#load RGerman stop words\n",
    "stopWords = set(stopwords.words('german')) #153 stop words\n",
    "wordsFiltered = []\n",
    "\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    "wordsLanguage = []\n",
    "for word in wordsFiltered:\n",
    "    if len(word) <= 14 and len(word) > 2:\n",
    "        wordsLanguage.append(word)\n",
    "print(wordsLanguage[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sätzen', 'umplatzierung', 'ankündigte', 'redewendungen', 'rheidol', 'dieckmann', 'hol-', 'schöpfer', 'geschärfte', 'enzymgruppe', 'sopranlage', 'turicen', 'eingehen', 'fünfundvierzig', 'gauck', 'prangins', 'worn', 'jhwh-kult', 'ecossaise', 'zitronenbaum', 'chaotische', 'mugby', 'elterlichen', 'beheimatete', 'szintigramm', 'schutzhauses', 'gladiator', 'sprengstoffen', 'webstühle', 'dub', 'shut', 'erregertyp', 'norodom', 'eurasischer', 'thieringsch', 'energiesparen', 'wattens-fc', 'umlaufbahn', 'verdächtigt', 'genießend', 'stoff', 'legitimierte', 'xenophanes', 'mendelssohn', 'abgewählt', 'schöne', 'sannicandro', 'klärschlamm', 'kolonien', 'pflanze', 'otway', 'fabeltiere', 'wasserstände', 'abzweigen-', 'übergangs-', 'donnersberg', 'cdu', '-bearbeitung', 'kongresssälen', 'pfister', 'schulstunde', 'überstellte', 'motivkomplex', 'grundentwurf', 'unifying', 'klemp', 'erdaltertums', 'wädenswil', 'demgemäß', 'nahegebracht', 'u-matic', 'anpreisungen', 'klosterstätte', 'tour-direktor', 'stiftsruine', 'belakane', 'disputationen', 'noor', 'kettenbrücke', 'kehlfleck', 'barkeeper', 'utraquisten', 'gearbeiteten', 'pløyen', 'langwierige', 'geschnitzte', 'faszikeln', 'pfeilhof', 'rahman', 'changes', 'striches', 'knuckleduster', 'vischering', 'ddr-mark', 'verherrlicht', 'wärmelieferant', 'ast', 'gentle', 'turbulenzen', 'heiztechnik']\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate words\n",
    "uniqueWordsLanguage = list(set(wordsLanguage))\n",
    "print(uniqueWordsLanguage[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('de_words.txt', 'w') as filehandle:\n",
    "    for listitem in wordsLanguage:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('de_words_noduplicates.txt', 'w') as filehandle:\n",
    "    for listitem in uniqueWordsLanguage:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['roche-sur-yon', 'roche-sur-yon', 'commune', 'centre-ouest', 'france', 'préfecture', 'département', 'vendée', 'région', 'pays', 'loire', 'arrosée', 'yon', 'affluents', 'riaillée', \"l'ornay\", 'tributaire', 'soivre', 'roche-sur-yon', 'doit', 'physionomie', 'actuelle', 'fait', \"d'un\", 'petit', 'bourg', 'cité', 'moderne', 'basée', 'plan', 'régulier', 'forme', 'pentagone', 'dotée', \"d'édifices\", 'publics', 'imposants', 'préfecture', 'hôtel', 'ville', 'théâtre', 'tribunaux', 'lycée', 'église', 'saint-louis', 'etc', 'répartis', 'autour', \"d'une\", 'vaste', 'esplanade', 'centrale', 'place', 'napoléon', 'ville', 'fondée', 'décret', 'impérial', 'promue', 'cette', 'date', 'préfecture', 'vendée', 'remplacement', 'ville', 'napoléonienne', 'conçue', 'ingénieurs', 'nom', 'source', 'querelles', 'gré', 'changements', 'politiques', 'agitent', 'débaptisée', 'rebaptisée', 'huit', 'reprises', 'roche-sur-yon', 'napoléon', 'sous', 'premier', 'empire', 'cent-jours', 'deuxième', 'république', 'bourbon-vendée', 'sous', 'restauration', 'sous', 'second', 'empire', 'reprend', 'nom', \"d'origine\", 'principal', 'centre', 'urbain', 'département']\n"
     ]
    }
   ],
   "source": [
    "text = open(\"./training/clean/french\").read()\n",
    "tokens = word_tokenize(text)\n",
    "words = [word.lower() for word in tokens] # memove capitalization\n",
    "#load French stop words\n",
    "stopWords = set(stopwords.words('french')) #153 stop words\n",
    "wordsFiltered = []\n",
    "\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    "# remove words < 2 and >14 charachers\n",
    "wordsLanguage = []\n",
    "for word in wordsFiltered:\n",
    "    if len(word) <= 14 and len(word) > 2:\n",
    "        wordsLanguage.append(word)\n",
    "print(wordsLanguage[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['processeur', 'wahlöö', 'dépecé', 'mnémon', 'effacée', 'appuyés', 'machonnerie', \"s'éleva\", \"s'aperçoit\", 'lins', 'pédagogie', 'sacræ', 'manquée', \"l'argenterie\", 'brassard', 'güines', 'circassienne', 'gellar', 'invoquait', 'tapée', 'permission', 'gyeongnam', 'cottages', 'gladiator', 'absente', 'plissement', 'satisfera', 'rougier', 'paterre', 'glacial', 'dub', 'souhaita', 'saint-valentin', \"s'invagine\", 'grandrupt', 'intégralement', 'aïkikaï', 'mendelssohn', 'figurent', 'caignault', 'sodales', 'grésillement', 'guibertum', 'visitable', 'lauterbachii', 'scientifiques', 'vecchiano', 'munerarii', 'cdu', 'pfister', \"l'asie\", 'numérisées', 'bansko', \"l'empêchent\", 'vigeois', 'rntbci', 'néry', 'génitif', 'modonna', \"l'uruguay\", 'masius', 'noor', 'providentiel', 'saulieu', 'hüttikon', 'situait', 'marquantes', 'préalpines', 'christianisée', 'ccdm', 'fluctue', \"d'enrichir\", 'rahman', 'bls', 'changes', \"s'enfoncent\", 'direct-to-dvd', 'décroître', 'légère', 'borca', 'javanais', 'favorable', 'réinstituée', 'normatives', 'globule', 'émanciper', 'polyphème', 'transitive', 'solstice', 'chouan', 'revigorante', 'evian', 'drainaient', 'paléographie', 'réimprimée', 'tôtes', 'perdent', 'nargué', 'jardin', 'façons']\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate words\n",
    "uniqueWordsLanguage = list(set(wordsLanguage))\n",
    "print(uniqueWordsLanguage[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fr_words.txt', 'w') as filehandle:\n",
    "    for listitem in wordsLanguage:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fr_words_noduplicates.txt', 'w') as filehandle:\n",
    "    for listitem in uniqueWordsLanguage:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
